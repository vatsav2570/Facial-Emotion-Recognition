{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1732825,"sourceType":"datasetVersion","datasetId":1028436},{"sourceId":8430413,"sourceType":"datasetVersion","datasetId":5020464},{"sourceId":8430552,"sourceType":"datasetVersion","datasetId":5020580}],"dockerImageVersionId":30097,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# import required packages\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import LeakyReLU\n\n# Initialize image data generator with rescaling\ntrain_data_gen = ImageDataGenerator(rescale=1./255)\nvalidation_data_gen = ImageDataGenerator(rescale=1./255)\n\n# Preprocess all test images\ntrain_generator = train_data_gen.flow_from_directory(\n        '/kaggle/input/emotion-detection-fer/train',\n        target_size=(48, 48),\n        batch_size=64,\n        color_mode=\"grayscale\",\n        class_mode='categorical')\n\n# Preprocess all train images\nvalidation_generator = validation_data_gen.flow_from_directory(\n        '/kaggle/input/emotion-detection-fer/test',\n        target_size=(48, 48),\n        batch_size=64,\n        color_mode=\"grayscale\",\n        class_mode='categorical')\n\n# create model structure\nemotion_model = Sequential()\n\nemotion_model.add(Conv2D(32, kernel_size=(3, 3), activation=LeakyReLU(alpha=0.1), input_shape=(48, 48, 1)))\nemotion_model.add(Conv2D(64, kernel_size=(3, 3), activation=LeakyReLU(alpha=0.1)))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation=LeakyReLU(alpha=0.1)))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation=LeakyReLU(alpha=0.1)))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Flatten())\nemotion_model.add(Dense(1024, activation=LeakyReLU(alpha=0.1)))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(7, activation='softmax'))\n\ncv2.ocl.setUseOpenCL(False)\n\nemotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n\n# Train the neural network/model\nemotion_model_info = emotion_model.fit_generator(\n        train_generator,\n        steps_per_epoch=28709 // 64,\n        epochs=100,\n        validation_data=validation_generator,\n        validation_steps=7178 // 64)\n\n# save model structure in jason file\nmodel_json = emotion_model.to_json()\nwith open(\"emotion_model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# save trained model weight in .h5 file\nemotion_model.save_weights('emotion_model.h5')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:33:18.462307Z","iopub.execute_input":"2024-05-16T12:33:18.462726Z","iopub.status.idle":"2024-05-16T13:28:06.432002Z","shell.execute_reply.started":"2024-05-16T12:33:18.462639Z","shell.execute_reply":"2024-05-16T13:28:06.431154Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found 28709 images belonging to 7 classes.\nFound 7178 images belonging to 7 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n448/448 [==============================] - 155s 332ms/step - loss: 1.8243 - accuracy: 0.2492 - val_loss: 1.6611 - val_accuracy: 0.3523\nEpoch 2/100\n448/448 [==============================] - 38s 85ms/step - loss: 1.6426 - accuracy: 0.3617 - val_loss: 1.5382 - val_accuracy: 0.4201\nEpoch 3/100\n448/448 [==============================] - 33s 75ms/step - loss: 1.5449 - accuracy: 0.4087 - val_loss: 1.4593 - val_accuracy: 0.4445\nEpoch 4/100\n448/448 [==============================] - 33s 73ms/step - loss: 1.4644 - accuracy: 0.4415 - val_loss: 1.4025 - val_accuracy: 0.4621\nEpoch 5/100\n448/448 [==============================] - 33s 73ms/step - loss: 1.4019 - accuracy: 0.4709 - val_loss: 1.3481 - val_accuracy: 0.4904\nEpoch 6/100\n448/448 [==============================] - 32s 71ms/step - loss: 1.3372 - accuracy: 0.4946 - val_loss: 1.3124 - val_accuracy: 0.4957\nEpoch 7/100\n448/448 [==============================] - 32s 71ms/step - loss: 1.2919 - accuracy: 0.5166 - val_loss: 1.2649 - val_accuracy: 0.5209\nEpoch 8/100\n448/448 [==============================] - 33s 73ms/step - loss: 1.2528 - accuracy: 0.5278 - val_loss: 1.2478 - val_accuracy: 0.5278\nEpoch 9/100\n448/448 [==============================] - 34s 76ms/step - loss: 1.2171 - accuracy: 0.5459 - val_loss: 1.2307 - val_accuracy: 0.5318\nEpoch 10/100\n448/448 [==============================] - 30s 68ms/step - loss: 1.1743 - accuracy: 0.5580 - val_loss: 1.1971 - val_accuracy: 0.5445\nEpoch 11/100\n448/448 [==============================] - 30s 67ms/step - loss: 1.1577 - accuracy: 0.5652 - val_loss: 1.1894 - val_accuracy: 0.5473\nEpoch 12/100\n448/448 [==============================] - 30s 68ms/step - loss: 1.1250 - accuracy: 0.5814 - val_loss: 1.1557 - val_accuracy: 0.5639\nEpoch 13/100\n448/448 [==============================] - 31s 69ms/step - loss: 1.0892 - accuracy: 0.5955 - val_loss: 1.1484 - val_accuracy: 0.5653\nEpoch 14/100\n448/448 [==============================] - 31s 68ms/step - loss: 1.0723 - accuracy: 0.5993 - val_loss: 1.1462 - val_accuracy: 0.5646\nEpoch 15/100\n448/448 [==============================] - 32s 71ms/step - loss: 1.0502 - accuracy: 0.6072 - val_loss: 1.1286 - val_accuracy: 0.5767\nEpoch 16/100\n448/448 [==============================] - 32s 71ms/step - loss: 1.0195 - accuracy: 0.6192 - val_loss: 1.1135 - val_accuracy: 0.5759\nEpoch 17/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.9933 - accuracy: 0.6355 - val_loss: 1.1053 - val_accuracy: 0.5802\nEpoch 18/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.9700 - accuracy: 0.6449 - val_loss: 1.0988 - val_accuracy: 0.5831\nEpoch 19/100\n448/448 [==============================] - 33s 74ms/step - loss: 0.9594 - accuracy: 0.6423 - val_loss: 1.0931 - val_accuracy: 0.5911\nEpoch 20/100\n448/448 [==============================] - 35s 77ms/step - loss: 0.9285 - accuracy: 0.6573 - val_loss: 1.1002 - val_accuracy: 0.5919\nEpoch 21/100\n448/448 [==============================] - 31s 68ms/step - loss: 0.8971 - accuracy: 0.6671 - val_loss: 1.0870 - val_accuracy: 0.5917\nEpoch 22/100\n448/448 [==============================] - 31s 68ms/step - loss: 0.8689 - accuracy: 0.6835 - val_loss: 1.0830 - val_accuracy: 0.5974\nEpoch 23/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.8625 - accuracy: 0.6849 - val_loss: 1.0775 - val_accuracy: 0.5984\nEpoch 24/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.8429 - accuracy: 0.6861 - val_loss: 1.0924 - val_accuracy: 0.5993\nEpoch 25/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.8075 - accuracy: 0.7006 - val_loss: 1.0735 - val_accuracy: 0.6049\nEpoch 26/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.8038 - accuracy: 0.7052 - val_loss: 1.0745 - val_accuracy: 0.6035\nEpoch 27/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.7787 - accuracy: 0.7120 - val_loss: 1.0814 - val_accuracy: 0.6011\nEpoch 28/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.7537 - accuracy: 0.7263 - val_loss: 1.0861 - val_accuracy: 0.6090\nEpoch 29/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.7303 - accuracy: 0.7336 - val_loss: 1.0852 - val_accuracy: 0.6084\nEpoch 30/100\n448/448 [==============================] - 31s 70ms/step - loss: 0.7145 - accuracy: 0.7397 - val_loss: 1.0845 - val_accuracy: 0.6098\nEpoch 31/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.6991 - accuracy: 0.7414 - val_loss: 1.0929 - val_accuracy: 0.6112\nEpoch 32/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.6771 - accuracy: 0.7461 - val_loss: 1.0954 - val_accuracy: 0.6101\nEpoch 33/100\n448/448 [==============================] - 30s 66ms/step - loss: 0.6625 - accuracy: 0.7567 - val_loss: 1.0889 - val_accuracy: 0.6151\nEpoch 34/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.6478 - accuracy: 0.7634 - val_loss: 1.1078 - val_accuracy: 0.6152\nEpoch 35/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.6155 - accuracy: 0.7758 - val_loss: 1.0904 - val_accuracy: 0.6115\nEpoch 36/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.6074 - accuracy: 0.7772 - val_loss: 1.0947 - val_accuracy: 0.6150\nEpoch 37/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.5874 - accuracy: 0.7861 - val_loss: 1.1119 - val_accuracy: 0.6143\nEpoch 38/100\n448/448 [==============================] - 30s 68ms/step - loss: 0.5726 - accuracy: 0.7920 - val_loss: 1.1310 - val_accuracy: 0.6133\nEpoch 39/100\n448/448 [==============================] - 32s 70ms/step - loss: 0.5552 - accuracy: 0.7957 - val_loss: 1.1169 - val_accuracy: 0.6168\nEpoch 40/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.5437 - accuracy: 0.8032 - val_loss: 1.1417 - val_accuracy: 0.6180\nEpoch 41/100\n448/448 [==============================] - 31s 68ms/step - loss: 0.5318 - accuracy: 0.8065 - val_loss: 1.1504 - val_accuracy: 0.6205\nEpoch 42/100\n448/448 [==============================] - 35s 77ms/step - loss: 0.5146 - accuracy: 0.8144 - val_loss: 1.1443 - val_accuracy: 0.6191\nEpoch 43/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.5049 - accuracy: 0.8132 - val_loss: 1.1689 - val_accuracy: 0.6196\nEpoch 44/100\n448/448 [==============================] - 29s 65ms/step - loss: 0.4944 - accuracy: 0.8194 - val_loss: 1.1565 - val_accuracy: 0.6177\nEpoch 45/100\n448/448 [==============================] - 30s 66ms/step - loss: 0.4818 - accuracy: 0.8244 - val_loss: 1.1709 - val_accuracy: 0.6217\nEpoch 46/100\n448/448 [==============================] - 29s 65ms/step - loss: 0.4605 - accuracy: 0.8316 - val_loss: 1.1690 - val_accuracy: 0.6186\nEpoch 47/100\n448/448 [==============================] - 31s 68ms/step - loss: 0.4492 - accuracy: 0.8374 - val_loss: 1.1713 - val_accuracy: 0.6219\nEpoch 48/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.4374 - accuracy: 0.8415 - val_loss: 1.1973 - val_accuracy: 0.6187\nEpoch 49/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.4211 - accuracy: 0.8496 - val_loss: 1.1979 - val_accuracy: 0.6191\nEpoch 50/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.4258 - accuracy: 0.8419 - val_loss: 1.2131 - val_accuracy: 0.6191\nEpoch 51/100\n448/448 [==============================] - 31s 70ms/step - loss: 0.4136 - accuracy: 0.8512 - val_loss: 1.2123 - val_accuracy: 0.6221\nEpoch 52/100\n448/448 [==============================] - 29s 65ms/step - loss: 0.3942 - accuracy: 0.8579 - val_loss: 1.2055 - val_accuracy: 0.6254\nEpoch 53/100\n448/448 [==============================] - 30s 68ms/step - loss: 0.3900 - accuracy: 0.8577 - val_loss: 1.2020 - val_accuracy: 0.6229\nEpoch 54/100\n448/448 [==============================] - 29s 65ms/step - loss: 0.3791 - accuracy: 0.8604 - val_loss: 1.2190 - val_accuracy: 0.6200\nEpoch 55/100\n448/448 [==============================] - 29s 66ms/step - loss: 0.3713 - accuracy: 0.8682 - val_loss: 1.2429 - val_accuracy: 0.6250\nEpoch 56/100\n448/448 [==============================] - 29s 66ms/step - loss: 0.3590 - accuracy: 0.8706 - val_loss: 1.2534 - val_accuracy: 0.6215\nEpoch 57/100\n448/448 [==============================] - 31s 68ms/step - loss: 0.3439 - accuracy: 0.8735 - val_loss: 1.2404 - val_accuracy: 0.6267\nEpoch 58/100\n448/448 [==============================] - 30s 66ms/step - loss: 0.3313 - accuracy: 0.8829 - val_loss: 1.2443 - val_accuracy: 0.6219\nEpoch 59/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.3345 - accuracy: 0.8789 - val_loss: 1.2549 - val_accuracy: 0.6228\nEpoch 60/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.3225 - accuracy: 0.8817 - val_loss: 1.2690 - val_accuracy: 0.6254\nEpoch 61/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.3245 - accuracy: 0.8856 - val_loss: 1.2638 - val_accuracy: 0.6264\nEpoch 62/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.3247 - accuracy: 0.8800 - val_loss: 1.2973 - val_accuracy: 0.6302\nEpoch 63/100\n448/448 [==============================] - 33s 74ms/step - loss: 0.3095 - accuracy: 0.8869 - val_loss: 1.2969 - val_accuracy: 0.6253\nEpoch 64/100\n448/448 [==============================] - 33s 74ms/step - loss: 0.3008 - accuracy: 0.8928 - val_loss: 1.2801 - val_accuracy: 0.6186\nEpoch 65/100\n448/448 [==============================] - 33s 73ms/step - loss: 0.2865 - accuracy: 0.8990 - val_loss: 1.3117 - val_accuracy: 0.6211\nEpoch 66/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.2861 - accuracy: 0.9005 - val_loss: 1.3583 - val_accuracy: 0.6258\nEpoch 67/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.2891 - accuracy: 0.8959 - val_loss: 1.3335 - val_accuracy: 0.6271\nEpoch 68/100\n448/448 [==============================] - 30s 68ms/step - loss: 0.2713 - accuracy: 0.9034 - val_loss: 1.3415 - val_accuracy: 0.6219\nEpoch 69/100\n448/448 [==============================] - 30s 66ms/step - loss: 0.2718 - accuracy: 0.9006 - val_loss: 1.3470 - val_accuracy: 0.6267\nEpoch 70/100\n448/448 [==============================] - 31s 70ms/step - loss: 0.2767 - accuracy: 0.9025 - val_loss: 1.3446 - val_accuracy: 0.6275\nEpoch 71/100\n448/448 [==============================] - 33s 74ms/step - loss: 0.2608 - accuracy: 0.9055 - val_loss: 1.3629 - val_accuracy: 0.6236\nEpoch 72/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.2604 - accuracy: 0.9057 - val_loss: 1.3759 - val_accuracy: 0.6256\nEpoch 73/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.2509 - accuracy: 0.9106 - val_loss: 1.3582 - val_accuracy: 0.6307\nEpoch 74/100\n448/448 [==============================] - 32s 70ms/step - loss: 0.2579 - accuracy: 0.9073 - val_loss: 1.3460 - val_accuracy: 0.6304\nEpoch 75/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.2539 - accuracy: 0.9081 - val_loss: 1.3857 - val_accuracy: 0.6288\nEpoch 76/100\n448/448 [==============================] - 31s 70ms/step - loss: 0.2361 - accuracy: 0.9159 - val_loss: 1.3879 - val_accuracy: 0.6275\nEpoch 77/100\n448/448 [==============================] - 31s 69ms/step - loss: 0.2425 - accuracy: 0.9129 - val_loss: 1.3851 - val_accuracy: 0.6250\nEpoch 78/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.2367 - accuracy: 0.9153 - val_loss: 1.3965 - val_accuracy: 0.6258\nEpoch 79/100\n448/448 [==============================] - 30s 68ms/step - loss: 0.2308 - accuracy: 0.9153 - val_loss: 1.4082 - val_accuracy: 0.6258\nEpoch 80/100\n448/448 [==============================] - 31s 68ms/step - loss: 0.2277 - accuracy: 0.9202 - val_loss: 1.4139 - val_accuracy: 0.6253\nEpoch 81/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.2250 - accuracy: 0.9220 - val_loss: 1.4147 - val_accuracy: 0.6270\nEpoch 82/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.2142 - accuracy: 0.9262 - val_loss: 1.4243 - val_accuracy: 0.6264\nEpoch 83/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.2196 - accuracy: 0.9215 - val_loss: 1.4087 - val_accuracy: 0.6218\nEpoch 84/100\n448/448 [==============================] - 30s 66ms/step - loss: 0.2122 - accuracy: 0.9254 - val_loss: 1.4688 - val_accuracy: 0.6289\nEpoch 85/100\n448/448 [==============================] - 29s 65ms/step - loss: 0.2063 - accuracy: 0.9284 - val_loss: 1.4696 - val_accuracy: 0.6256\nEpoch 86/100\n448/448 [==============================] - 31s 68ms/step - loss: 0.2004 - accuracy: 0.9281 - val_loss: 1.4280 - val_accuracy: 0.6279\nEpoch 87/100\n448/448 [==============================] - 32s 72ms/step - loss: 0.2011 - accuracy: 0.9298 - val_loss: 1.4461 - val_accuracy: 0.6204\nEpoch 88/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.2033 - accuracy: 0.9279 - val_loss: 1.4391 - val_accuracy: 0.6265\nEpoch 89/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.1976 - accuracy: 0.9295 - val_loss: 1.4712 - val_accuracy: 0.6263\nEpoch 90/100\n448/448 [==============================] - 30s 68ms/step - loss: 0.1971 - accuracy: 0.9300 - val_loss: 1.4465 - val_accuracy: 0.6228\nEpoch 91/100\n448/448 [==============================] - 30s 66ms/step - loss: 0.1890 - accuracy: 0.9325 - val_loss: 1.4898 - val_accuracy: 0.6272\nEpoch 92/100\n448/448 [==============================] - 30s 66ms/step - loss: 0.1893 - accuracy: 0.9331 - val_loss: 1.4925 - val_accuracy: 0.6277\nEpoch 93/100\n448/448 [==============================] - 30s 67ms/step - loss: 0.1838 - accuracy: 0.9346 - val_loss: 1.4800 - val_accuracy: 0.6217\nEpoch 94/100\n448/448 [==============================] - 30s 68ms/step - loss: 0.1864 - accuracy: 0.9356 - val_loss: 1.5052 - val_accuracy: 0.6290\nEpoch 95/100\n448/448 [==============================] - 32s 71ms/step - loss: 0.1796 - accuracy: 0.9385 - val_loss: 1.5166 - val_accuracy: 0.6275\nEpoch 96/100\n448/448 [==============================] - 33s 74ms/step - loss: 0.1859 - accuracy: 0.9335 - val_loss: 1.4907 - val_accuracy: 0.6332\nEpoch 97/100\n448/448 [==============================] - 32s 70ms/step - loss: 0.1791 - accuracy: 0.9379 - val_loss: 1.4816 - val_accuracy: 0.6282\nEpoch 98/100\n448/448 [==============================] - 31s 70ms/step - loss: 0.1800 - accuracy: 0.9355 - val_loss: 1.4999 - val_accuracy: 0.6244\nEpoch 99/100\n448/448 [==============================] - 34s 75ms/step - loss: 0.1787 - accuracy: 0.9358 - val_loss: 1.4981 - val_accuracy: 0.6286\nEpoch 100/100\n448/448 [==============================] - 31s 70ms/step - loss: 0.1776 - accuracy: 0.9386 - val_loss: 1.4932 - val_accuracy: 0.6277\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom keras.models import model_from_json\nfrom keras.layers import LeakyReLU\n\n# Define the emotion dictionary\nemotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n\n# Load the pre-trained model from JSON and weights\njson_file = open('/kaggle/working/emotion_model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\n\n\n# Load the pre-trained model from JSON and weights with custom_objects\nemotion_model = model_from_json(loaded_model_json, custom_objects={'LeakyReLU': LeakyReLU})\nemotion_model.load_weights(\"/kaggle/working/emotion_model.h5\")\nprint(\"Loaded model from disk\")\n\n\n# Initialize face detector\nface_detector = cv2.CascadeClassifier('/kaggle/input/default/haarcascade_frontalface_default.xml')\n\n# Start the video capture (change video path as needed)\ncap = cv2.VideoCapture(\"/kaggle/input/sample-video/WIN_20230205_21_34_30_Pro.mp4\")\n\n# Define the codec and create VideoWriter object\noutput_path = '/kaggle/working/output_video_with_emotions.avi'\ncodec = cv2.VideoWriter_fourcc(*'XVID')\noutput_video = cv2.VideoWriter(output_path, codec, 30.0, (1280, 720))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Resize frame if needed\n    frame = cv2.resize(frame, (1280, 720))\n\n    # Convert frame to grayscale for face detection\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # Detect faces in the frame\n    num_faces = face_detector.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)\n\n    # Process each detected face\n    for (x, y, w, h) in num_faces:\n        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (0, 255, 0), 4)\n        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n\n        # Predict emotions for the face\n        emotion_prediction = emotion_model.predict(cropped_img)\n        maxindex = int(np.argmax(emotion_prediction))\n        cv2.putText(frame, emotion_dict[maxindex], (x+5, y-20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n\n    # Write the frame with annotations to the output video\n    output_video.write(frame)\n\ncap.release()\noutput_video.release()\n\n# Print the path to the output video\nprint(f\"Output video saved at: {output_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T13:42:51.090569Z","iopub.execute_input":"2024-05-16T13:42:51.090991Z","iopub.status.idle":"2024-05-16T13:43:04.411438Z","shell.execute_reply.started":"2024-05-16T13:42:51.090961Z","shell.execute_reply":"2024-05-16T13:43:04.410347Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Loaded model from disk\nOutput video saved at: /kaggle/working/output_video_with_emotions.avi\n","output_type":"stream"}]}]}